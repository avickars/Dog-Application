{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "845a439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import DogIdentificationModel\n",
    "from params import DEVICE, CPU_DEVICE\n",
    "# from data_loader_test import DogsDataSet_Test\n",
    "# from data_loader_test_closest import DogsDataSet_Test\n",
    "from data_loader_test_breed import DogsDataSet_Test\n",
    "from loss import sigmoidL2\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49782544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model\n",
    "model = DogIdentificationModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7eacec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving to training device\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e46e4888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load('dog-identification-model-triplet.pt')\n",
    "# checkpoint = torch.load('dog-identification-model-breed.pt')\n",
    "checkpoint = torch.load('dog-identification-model.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "trainMeanLosses = checkpoint['trainMeanLosses']\n",
    "validationMeanLosses = checkpoint['validationMeanLosses']"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting model training results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a63c1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Epoch v. Training/Validation Loss')\n",
    "plt.plot(checkpoint['trainMeanLosses'], label='Train')\n",
    "plt.plot(checkpoint['validationMeanLosses'], label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Triplet Loss')\n",
    "plt.legend()\n",
    "plt.savefig('crossentropy_training.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Computing Test Results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab2d7a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d4d47ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the validation data loader\n",
    "validationData = DogsDataSet_Test(dataType='test',filterBreed=True)\n",
    "\n",
    "# Defining the Validation data loader\n",
    "validationLoader = torch.utils.data.DataLoader(validationData, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16cabf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "model = model.eval()\n",
    "\n",
    "results = []\n",
    "labels = []\n",
    "\n",
    "# Defining loop to get the nice progress bar\n",
    "loop = tqdm(enumerate(validationLoader), total=len(validationLoader), leave=True)\n",
    "\n",
    "# Turning off the gradient\n",
    "with torch.no_grad():\n",
    "    for batchIndex, (img1, img2, label) in loop:\n",
    "        img1 = img1.to(DEVICE)\n",
    "        img2 = img2.to(DEVICE)\n",
    "\n",
    "        img1Encoding = model(img1)\n",
    "        img2Encoding = model(img2)       \n",
    "        \n",
    "        \n",
    "        distance = sigmoidL2(img1Encoding,img2Encoding)\n",
    "        \n",
    "        distance = distance.to(CPU_DEVICE)\n",
    "        \n",
    "        results += distance.tolist()\n",
    "        \n",
    "        labels += label.squeeze().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plotting ROC Curve"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d372494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CITATION: https://www.statology.org/plot-roc-curve-python/\n",
    "fpr, tpr, threshold = metrics.roc_curve(labels,results)\n",
    "auc = metrics.roc_auc_score(labels,results)\n",
    "\n",
    "bestIndex = list(threshold).index(0.6744843125343323)\n",
    "\n",
    "plt.plot(fpr,tpr,label=\"AUC=\"+str(round(auc,2)))\n",
    "plt.scatter(fpr[bestIndex], tpr[bestIndex], marker='o', color='r',label=\"Optimum Classification Threshold=\"+str(0.6744843125343323))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.title('Validation Data ROC Curve')\n",
    "# plt.savefig('roc_curve_validation_triplet.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plotting Line Plot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75b2c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['results'] = results\n",
    "df['yaxis'] = np.zeros(len(results))\n",
    "df['label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8f6c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df[df['label'] == 1]['results'], \n",
    "            df[df['label'] == 1]['yaxis'],\n",
    "            c='r',\n",
    "            alpha=0.1, label=\"Different Dog\")\n",
    "\n",
    "plt.scatter(df[df['label'] == 0]['results'], \n",
    "            df[df['label'] == 0]['yaxis'],\n",
    "            c='g',\n",
    "            alpha=0.1,label=\"Same Dog\")\n",
    "plt.legend()\n",
    "plt.yticks([])\n",
    "plt.xlabel('Similarity Score')\n",
    "plt.title('Similarity Scores of Same and Different Dog Comparisons')\n",
    "# plt.savefig('crossentropy_lineplot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Determining Optimum CutOff"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48928b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.632717490196228]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def Find_Optimal_Cutoff(target, predicted):\n",
    "    # CITATION: https://stackoverflow.com/questions/28719067/roc-curve-and-cut-off-point-python\n",
    "    \"\"\" Find the optimal probability cutoff point for a classification model related to event rate\n",
    "    Parameters\n",
    "    ----------\n",
    "    target : Matrix with dependent or target data, where rows are observations\n",
    "\n",
    "    predicted : Matrix with predicted data, where rows are observations\n",
    "\n",
    "    Returns\n",
    "    -------     \n",
    "    list type, with optimal cutoff value\n",
    "        \n",
    "    \"\"\"\n",
    "    fpr, tpr, threshold = metrics.roc_curve(target, predicted)\n",
    "    i = np.arange(len(tpr)) \n",
    "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
    "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "    return list(roc_t['threshold']) \n",
    "\n",
    "Find_Optimal_Cutoff(labels, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "601c8725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8285714285714286"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(labels,[0 if i < 0.6744843125343323 else 1 for i in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b59acf8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(labels,[0 if i < 0.6744843125343323 else 1 for i in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ff9ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}