{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = 'vit_b_16_based_model2.pt'\n",
    "\n",
    "data_dir = '../../../stanford_dogs_new/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import Markdown\n",
    "\n",
    "from PIL import Image\n",
    "import PIL.Image\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the vit_b_16 based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /home/rka73/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0044298e7758490182f7f6b187f64ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=346328529.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): Sequential(\n",
       "      (encoder_layer_0): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_1): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_2): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_3): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_4): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_5): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_6): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_7): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_8): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_9): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_10): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_11): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (heads): Sequential(\n",
       "    (head): Linear(in_features=768, out_features=120, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit_b_16_loaded = models.vit_b_16(pretrained=True)\n",
    "\n",
    "for param in vit_b_16_loaded.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# vit_b_16_loaded.head = nn.Linear(in_features=768, out_features=120, bias=True)\n",
    "feature_extractor = nn.Sequential(*list(vit_b_16_loaded.children())[-1:])\n",
    "# feature_extractor[0]\n",
    "feature_extractor[0].head = nn.Linear(in_features=768, out_features=120, bias=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "vit_b_16_loaded = vit_b_16_loaded.to(device)\n",
    "\n",
    "\n",
    "\n",
    "vit_b_16_loaded.load_state_dict(torch.load('vit_b_16_based_model2.pt'), strict=False)\n",
    "vit_b_16_loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vit_b_16_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the image for the model\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../../stanford_dogs_new/test'\n",
    "\n",
    "list_subfolders_with_paths = [f.path for f in os.scandir(path) if f.is_dir()]\n",
    "\n",
    "# gets the breed name from subfolders name like 'n02099429-curly-coated_retriever'\n",
    "def rename(name):\n",
    "    return ' '.join(' '.join(name.split('-')[1:]).split('_'))\n",
    "\n",
    "per_class_accuracy = dict()\n",
    "total_accuracy = 0\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for breed_dir in list_subfolders_with_paths:\n",
    "    \n",
    "    breed = rename(breed_dir.split('/')[-1])\n",
    "    \n",
    "    images = os.listdir(breed_dir)\n",
    "    \n",
    "    matched = False\n",
    "    matches = 0\n",
    "    total_images = len(images)\n",
    "\n",
    "    for image in images:\n",
    "\n",
    "        input_image = Image.open(breed_dir + '/' + image)\n",
    "\n",
    "\n",
    "        input_tensor = preprocess(input_image)\n",
    "        if torch.cuda.is_available():\n",
    "            input_tensor = Variable(input_tensor.cuda())\n",
    "\n",
    "        input_batch = input_tensor.unsqueeze(0)\n",
    "        out = model(input_batch)\n",
    "\n",
    "        probabilities = torch.nn.functional.softmax(out[0], dim=0)\n",
    "        # print(probabilities)\n",
    "\n",
    "        with open(\"../../stanford_dogs_breeds_classes_final.txt\", \"r\") as f:\n",
    "            categories = [s.strip() for s in f.readlines()]\n",
    "\n",
    "        predicted_breeds = []\n",
    "        top1_prob, top1_catid = torch.topk(probabilities, 1)\n",
    "        for i in range(top1_prob.size(0)):\n",
    "            # predicted_breeds.append([categories[top3_catid[i]], top3_prob[i].item()*100])\n",
    "            predicted_breed = categories[top1_catid[i]]\n",
    "            y_true.append(breed)\n",
    "            y_pred.append(predicted_breed)\n",
    "\n",
    "        # list to be used directly by the application (predicted_breed, probability)\n",
    "        # print(\"predicted_breeds are: \\n\", predicted_breed)\n",
    "        if breed == predicted_breed:\n",
    "            matched = True\n",
    "            matches = matches + 1\n",
    "\n",
    "        per_class_accuracy[breed] = matches / total_images * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual_breed</th>\n",
       "      <th>Predicted_breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pomeranian</td>\n",
       "      <td>Pomeranian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pomeranian</td>\n",
       "      <td>Pomeranian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pomeranian</td>\n",
       "      <td>Pomeranian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pomeranian</td>\n",
       "      <td>Pomeranian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pomeranian</td>\n",
       "      <td>Pomeranian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>papillon</td>\n",
       "      <td>papillon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>papillon</td>\n",
       "      <td>papillon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>papillon</td>\n",
       "      <td>papillon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>papillon</td>\n",
       "      <td>papillon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>papillon</td>\n",
       "      <td>papillon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2110 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual_breed Predicted_breed\n",
       "0      Pomeranian      Pomeranian\n",
       "1      Pomeranian      Pomeranian\n",
       "2      Pomeranian      Pomeranian\n",
       "3      Pomeranian      Pomeranian\n",
       "4      Pomeranian      Pomeranian\n",
       "...           ...             ...\n",
       "2105     papillon        papillon\n",
       "2106     papillon        papillon\n",
       "2107     papillon        papillon\n",
       "2108     papillon        papillon\n",
       "2109     papillon        papillon\n",
       "\n",
       "[2110 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list(zip(y_true, y_pred)),\n",
    "               columns =['Actual_breed', 'Predicted_breed'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22  0  0 ...  0  0  0]\n",
      " [ 0 16  0 ...  0  0  0]\n",
      " [ 0  0 20 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 16  0  0]\n",
      " [ 0  0  0 ...  0 13  0]\n",
      " [ 0  0  0 ...  0  0 14]]\n"
     ]
    }
   ],
   "source": [
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision, Recall and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                precision    recall  f1-score   support\n",
      "\n",
      "                  Afghan hound      0.880     0.917     0.898        24\n",
      "           African hunting dog      0.941     0.941     0.941        17\n",
      "                      Airedale      1.000     0.952     0.976        21\n",
      "American Staffordshire terrier      0.722     0.765     0.743        17\n",
      "                   Appenzeller      0.600     0.562     0.581        16\n",
      "            Australian terrier      0.938     0.750     0.833        20\n",
      "            Bedlington terrier      1.000     0.895     0.944        19\n",
      "          Bernese mountain dog      0.833     0.909     0.870        22\n",
      "              Blenheim spaniel      0.864     1.000     0.927        19\n",
      "                 Border collie      0.583     0.467     0.519        15\n",
      "                Border terrier      0.895     0.944     0.919        18\n",
      "                   Boston bull      0.783     0.947     0.857        19\n",
      "          Bouvier des Flandres      0.923     0.800     0.857        15\n",
      "             Brabancon griffon      1.000     0.938     0.968        16\n",
      "              Brittany spaniel      0.737     0.875     0.800        16\n",
      "                      Cardigan      1.000     0.562     0.720        16\n",
      "      Chesapeake Bay retriever      0.875     0.824     0.848        17\n",
      "                     Chihuahua      0.733     0.688     0.710        16\n",
      "                Dandie Dinmont      1.000     0.944     0.971        18\n",
      "                      Doberman      0.846     0.733     0.786        15\n",
      "              English foxhound      0.684     0.812     0.743        16\n",
      "                English setter      0.933     0.824     0.875        17\n",
      "              English springer      0.684     0.812     0.743        16\n",
      "                   EntleBucher      0.818     0.857     0.837        21\n",
      "                    Eskimo dog      0.389     0.467     0.424        15\n",
      "                French bulldog      0.765     0.812     0.788        16\n",
      "               German shepherd      1.000     0.750     0.857        16\n",
      "   German short haired pointer      0.875     0.875     0.875        16\n",
      "                 Gordon setter      0.938     0.938     0.938        16\n",
      "                    Great Dane      0.857     0.750     0.800        16\n",
      "                Great Pyrenees      0.737     0.636     0.683        22\n",
      "    Greater Swiss Mountain dog      0.800     0.706     0.750        17\n",
      "                  Ibizan hound      0.938     0.789     0.857        19\n",
      "                  Irish setter      0.889     1.000     0.941        16\n",
      "                 Irish terrier      0.789     0.882     0.833        17\n",
      "           Irish water spaniel      1.000     0.867     0.929        15\n",
      "               Irish wolfhound      1.000     0.682     0.811        22\n",
      "             Italian greyhound      0.739     0.895     0.810        19\n",
      "              Japanese spaniel      1.000     0.947     0.973        19\n",
      "            Kerry blue terrier      0.818     1.000     0.900        18\n",
      "            Labrador retriever      0.750     0.667     0.706        18\n",
      "              Lakeland terrier      0.800     0.800     0.800        20\n",
      "                      Leonberg      0.833     0.952     0.889        21\n",
      "                         Lhasa      0.867     0.684     0.765        19\n",
      "                   Maltese dog      0.852     0.885     0.868        26\n",
      "              Mexican hairless      1.000     0.875     0.933        16\n",
      "                  Newfoundland      0.905     0.950     0.927        20\n",
      "               Norfolk terrier      0.867     0.722     0.788        18\n",
      "            Norwegian elkhound      0.895     0.850     0.872        20\n",
      "               Norwich terrier      0.680     0.895     0.773        19\n",
      "          Old English sheepdog      0.895     1.000     0.944        17\n",
      "                      Pekinese      0.929     0.867     0.897        15\n",
      "                      Pembroke      0.739     0.895     0.810        19\n",
      "                    Pomeranian      0.957     1.000     0.978        22\n",
      "           Rhodesian ridgeback      0.789     0.833     0.811        18\n",
      "                    Rottweiler      0.882     0.938     0.909        16\n",
      "                 Saint Bernard      1.000     1.000     1.000        17\n",
      "                        Saluki      0.895     0.850     0.872        20\n",
      "                       Samoyed      0.870     0.909     0.889        22\n",
      "                Scotch terrier      0.769     0.625     0.690        16\n",
      "            Scottish deerhound      0.759     0.917     0.830        24\n",
      "              Sealyham terrier      1.000     0.857     0.923        21\n",
      "             Shetland sheepdog      0.789     0.938     0.857        16\n",
      "                      Shih Tzu      0.840     0.955     0.894        22\n",
      "                Siberian husky      0.455     0.500     0.476        20\n",
      "     Staffordshire bullterrier      0.733     0.688     0.710        16\n",
      "                Sussex spaniel      0.933     0.875     0.903        16\n",
      "               Tibetan mastiff      0.929     0.812     0.867        16\n",
      "               Tibetan terrier      0.950     0.905     0.927        21\n",
      "                  Walker hound      0.571     0.500     0.533        16\n",
      "                    Weimaraner      0.941     1.000     0.970        16\n",
      "        Welsh springer spaniel      1.000     0.733     0.846        15\n",
      "   West Highland white terrier      0.889     0.941     0.914        17\n",
      "             Yorkshire terrier      0.769     0.588     0.667        17\n",
      "                 affenpinscher      0.875     0.933     0.903        15\n",
      "                       basenji      0.864     0.905     0.884        21\n",
      "                        basset      0.800     0.667     0.727        18\n",
      "                        beagle      0.850     0.850     0.850        20\n",
      "       black and tan coonhound      0.933     0.875     0.903        16\n",
      "                    bloodhound      0.895     0.895     0.895        19\n",
      "                      bluetick      0.842     0.889     0.865        18\n",
      "                        borzoi      0.933     0.875     0.903        16\n",
      "                         boxer      0.929     0.812     0.867        16\n",
      "                        briard      0.867     0.812     0.839        16\n",
      "                  bull mastiff      1.000     0.938     0.968        16\n",
      "                         cairn      0.842     0.800     0.821        20\n",
      "                          chow      0.857     0.900     0.878        20\n",
      "                       clumber      0.882     1.000     0.938        15\n",
      "                cocker spaniel      0.684     0.812     0.743        16\n",
      "                        collie      0.643     0.562     0.600        16\n",
      "        curly coated retriever      0.750     0.750     0.750        16\n",
      "                         dhole      0.857     0.800     0.828        15\n",
      "                         dingo      0.812     0.812     0.812        16\n",
      "         flat coated retriever      0.833     0.625     0.714        16\n",
      "               giant schnauzer      0.700     0.875     0.778        16\n",
      "              golden retriever      0.722     0.867     0.788        15\n",
      "                   groenendael      1.000     1.000     1.000        15\n",
      "                      keeshond      1.000     1.000     1.000        16\n",
      "                        kelpie      0.765     0.812     0.788        16\n",
      "                      komondor      1.000     1.000     1.000        16\n",
      "                        kuvasz      0.778     0.933     0.848        15\n",
      "                      malamute      0.588     0.556     0.571        18\n",
      "                      malinois      0.929     0.867     0.897        15\n",
      "            miniature pinscher      0.714     0.789     0.750        19\n",
      "              miniature poodle      0.533     0.500     0.516        16\n",
      "           miniature schnauzer      0.682     0.938     0.789        16\n",
      "                    otterhound      0.786     0.688     0.733        16\n",
      "                      papillon      0.947     0.900     0.923        20\n",
      "                           pug      1.000     0.950     0.974        20\n",
      "                       redbone      0.632     0.800     0.706        15\n",
      "                    schipperke      0.875     0.875     0.875        16\n",
      "                 silky terrier      0.615     0.842     0.711        19\n",
      "   soft coated wheaten terrier      0.875     0.875     0.875        16\n",
      "               standard poodle      0.688     0.688     0.688        16\n",
      "            standard schnauzer      0.571     0.500     0.533        16\n",
      "                    toy poodle      0.733     0.688     0.710        16\n",
      "                   toy terrier      0.824     0.778     0.800        18\n",
      "                        vizsla      0.889     1.000     0.941        16\n",
      "                       whippet      0.812     0.684     0.743        19\n",
      "       wire haired fox terrier      0.737     0.875     0.800        16\n",
      "\n",
      "                      accuracy                          0.827      2110\n",
      "                     macro avg      0.832     0.824     0.824      2110\n",
      "                  weighted avg      0.834     0.827     0.827      2110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(y_true, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Macro F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8241098633862819"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_true, y_pred, average='macro')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Micro F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8274881516587678"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true, y_pred, average='micro')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8267903751732335"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohen Kappa Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8260104460787334"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "cohen_kappa_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Accuracy calculated from per class accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.42645461908234"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculated from per class accuracy\n",
    "total_accuracy = sum(per_class_accuracy.values())/120\n",
    "total_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per Breed Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 Breeds with least accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Eskimo dog', 46.666666666666664),\n",
       " ('Border collie', 46.666666666666664),\n",
       " ('miniature poodle', 50.0),\n",
       " ('Walker hound', 50.0),\n",
       " ('standard schnauzer', 50.0),\n",
       " ('Siberian husky', 50.0),\n",
       " ('malamute', 55.55555555555556),\n",
       " ('Appenzeller', 56.25),\n",
       " ('Cardigan', 56.25),\n",
       " ('collie', 56.25)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 10\n",
    "sorted(per_class_accuracy.items(), key=lambda x: x[1])[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 Breeds with most accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pomeranian', 100.0),\n",
       " ('Blenheim spaniel', 100.0),\n",
       " ('Irish setter', 100.0),\n",
       " ('clumber', 100.0),\n",
       " ('komondor', 100.0),\n",
       " ('Old English sheepdog', 100.0),\n",
       " ('keeshond', 100.0),\n",
       " ('Kerry blue terrier', 100.0),\n",
       " ('groenendael', 100.0),\n",
       " ('Weimaraner', 100.0)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 10\n",
    "sorted(per_class_accuracy.items(), key=lambda x: x[1], reverse=True)[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
