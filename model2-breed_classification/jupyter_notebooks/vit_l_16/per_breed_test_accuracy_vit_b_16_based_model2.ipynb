{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = 'vit_b_16_based_model2.pt'\n",
    "\n",
    "data_dir = '../../../stanford_dogs_new/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the vit_b_16 based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /home/rka73/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4cc83b156064d65b85dfad64bd3cb20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=346328529.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): Sequential(\n",
       "      (encoder_layer_0): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_1): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_2): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_3): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_4): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_5): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_6): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_7): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_8): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_9): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_10): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_11): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (heads): Sequential(\n",
       "    (head): Linear(in_features=768, out_features=120, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit_b_16_loaded = models.vit_b_16(pretrained=True)\n",
    "\n",
    "for param in vit_b_16_loaded.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# vit_b_16_loaded.head = nn.Linear(in_features=768, out_features=120, bias=True)\n",
    "feature_extractor = nn.Sequential(*list(vit_b_16_loaded.children())[-1:])\n",
    "# feature_extractor[0]\n",
    "feature_extractor[0].head = nn.Linear(in_features=768, out_features=120, bias=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "vit_b_16_loaded = vit_b_16_loaded.to(device)\n",
    "\n",
    "\n",
    "\n",
    "vit_b_16_loaded.load_state_dict(torch.load('vit_b_16_based_model2.pt'), strict=False)\n",
    "vit_b_16_loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vit_b_16_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pomeranian': 100.0,\n",
       " 'basset': 66.66666666666666,\n",
       " 'Japanese spaniel': 94.73684210526315,\n",
       " 'Bouvier des Flandres': 80.0,\n",
       " 'German shepherd': 75.0,\n",
       " 'Brabancon griffon': 93.75,\n",
       " 'Blenheim spaniel': 100.0,\n",
       " 'kelpie': 81.25,\n",
       " 'Shih Tzu': 95.45454545454545,\n",
       " 'curly coated retriever': 75.0,\n",
       " 'Lakeland terrier': 80.0,\n",
       " 'Irish setter': 100.0,\n",
       " 'German short haired pointer': 87.5,\n",
       " 'flat coated retriever': 62.5,\n",
       " 'Irish water spaniel': 86.66666666666667,\n",
       " 'Dandie Dinmont': 94.44444444444444,\n",
       " 'clumber': 100.0,\n",
       " 'Yorkshire terrier': 58.82352941176471,\n",
       " 'schipperke': 87.5,\n",
       " 'briard': 81.25,\n",
       " 'miniature poodle': 50.0,\n",
       " 'chow': 90.0,\n",
       " 'Saluki': 85.0,\n",
       " 'boxer': 81.25,\n",
       " 'Pekinese': 86.66666666666667,\n",
       " 'komondor': 100.0,\n",
       " 'Brittany spaniel': 87.5,\n",
       " 'black and tan coonhound': 87.5,\n",
       " 'Appenzeller': 56.25,\n",
       " 'Eskimo dog': 46.666666666666664,\n",
       " 'giant schnauzer': 87.5,\n",
       " 'Old English sheepdog': 100.0,\n",
       " 'Chihuahua': 68.75,\n",
       " 'miniature schnauzer': 93.75,\n",
       " 'redbone': 80.0,\n",
       " 'wire haired fox terrier': 87.5,\n",
       " 'Irish wolfhound': 68.18181818181817,\n",
       " 'dhole': 80.0,\n",
       " 'Pembroke': 89.47368421052632,\n",
       " 'keeshond': 100.0,\n",
       " 'kuvasz': 93.33333333333333,\n",
       " 'Sussex spaniel': 87.5,\n",
       " 'Samoyed': 90.9090909090909,\n",
       " 'malinois': 86.66666666666667,\n",
       " 'Staffordshire bullterrier': 68.75,\n",
       " 'bull mastiff': 93.75,\n",
       " 'Rottweiler': 93.75,\n",
       " 'West Highland white terrier': 94.11764705882352,\n",
       " 'bloodhound': 89.47368421052632,\n",
       " 'bluetick': 88.88888888888889,\n",
       " 'Australian terrier': 75.0,\n",
       " 'Lhasa': 68.42105263157895,\n",
       " 'silky terrier': 84.21052631578947,\n",
       " 'Greater Swiss Mountain dog': 70.58823529411765,\n",
       " 'Boston bull': 94.73684210526315,\n",
       " 'EntleBucher': 85.71428571428571,\n",
       " 'Tibetan mastiff': 81.25,\n",
       " 'soft coated wheaten terrier': 87.5,\n",
       " 'Italian greyhound': 89.47368421052632,\n",
       " 'Great Dane': 75.0,\n",
       " 'Doberman': 73.33333333333333,\n",
       " 'Bernese mountain dog': 90.9090909090909,\n",
       " 'whippet': 68.42105263157895,\n",
       " 'Shetland sheepdog': 93.75,\n",
       " 'American Staffordshire terrier': 76.47058823529412,\n",
       " 'French bulldog': 81.25,\n",
       " 'Cardigan': 56.25,\n",
       " 'Kerry blue terrier': 100.0,\n",
       " 'groenendael': 100.0,\n",
       " 'basenji': 90.47619047619048,\n",
       " 'cairn': 80.0,\n",
       " 'Tibetan terrier': 90.47619047619048,\n",
       " 'Welsh springer spaniel': 73.33333333333333,\n",
       " 'golden retriever': 86.66666666666667,\n",
       " 'English foxhound': 81.25,\n",
       " 'Rhodesian ridgeback': 83.33333333333334,\n",
       " 'miniature pinscher': 78.94736842105263,\n",
       " 'Walker hound': 50.0,\n",
       " 'Newfoundland': 95.0,\n",
       " 'standard poodle': 68.75,\n",
       " 'borzoi': 87.5,\n",
       " 'Border collie': 46.666666666666664,\n",
       " 'Norwich terrier': 89.47368421052632,\n",
       " 'Great Pyrenees': 63.63636363636363,\n",
       " 'Irish terrier': 88.23529411764706,\n",
       " 'Maltese dog': 88.46153846153845,\n",
       " 'otterhound': 68.75,\n",
       " 'beagle': 85.0,\n",
       " 'standard schnauzer': 50.0,\n",
       " 'Weimaraner': 100.0,\n",
       " 'Chesapeake Bay retriever': 82.35294117647058,\n",
       " 'English springer': 81.25,\n",
       " 'Norwegian elkhound': 85.0,\n",
       " 'Ibizan hound': 78.94736842105263,\n",
       " 'Siberian husky': 50.0,\n",
       " 'collie': 56.25,\n",
       " 'Scotch terrier': 62.5,\n",
       " 'Mexican hairless': 87.5,\n",
       " 'Afghan hound': 91.66666666666666,\n",
       " 'cocker spaniel': 81.25,\n",
       " 'pug': 95.0,\n",
       " 'toy terrier': 77.77777777777779,\n",
       " 'Sealyham terrier': 85.71428571428571,\n",
       " 'malamute': 55.55555555555556,\n",
       " 'dingo': 81.25,\n",
       " 'Scottish deerhound': 91.66666666666666,\n",
       " 'Norfolk terrier': 72.22222222222221,\n",
       " 'Leonberg': 95.23809523809523,\n",
       " 'Saint Bernard': 100.0,\n",
       " 'African hunting dog': 94.11764705882352,\n",
       " 'Gordon setter': 93.75,\n",
       " 'Border terrier': 94.44444444444444,\n",
       " 'toy poodle': 68.75,\n",
       " 'vizsla': 100.0,\n",
       " 'English setter': 82.35294117647058,\n",
       " 'Labrador retriever': 66.66666666666666,\n",
       " 'Bedlington terrier': 89.47368421052632,\n",
       " 'Airedale': 95.23809523809523,\n",
       " 'affenpinscher': 93.33333333333333,\n",
       " 'papillon': 90.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess the image for the model\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "path = '../../../stanford_dogs_new/test'\n",
    "\n",
    "list_subfolders_with_paths = [f.path for f in os.scandir(path) if f.is_dir()]\n",
    "\n",
    "# gets the breed name from subfolders name like 'n02099429-curly-coated_retriever'\n",
    "def rename(name):\n",
    "    return ' '.join(' '.join(name.split('-')[1:]).split('_'))\n",
    "\n",
    "per_class_accuracy = dict()\n",
    "total_accuracy = 0\n",
    "\n",
    "for breed_dir in list_subfolders_with_paths:\n",
    "    \n",
    "    breed = rename(breed_dir.split('/')[-1])\n",
    "    \n",
    "    images = os.listdir(breed_dir)\n",
    "    \n",
    "    matched = False\n",
    "    matches = 0\n",
    "    total_images = len(images)\n",
    "\n",
    "    for image in images:\n",
    "\n",
    "        input_image = Image.open(breed_dir + '/' + image)\n",
    "\n",
    "\n",
    "        input_tensor = preprocess(input_image)\n",
    "        if torch.cuda.is_available():\n",
    "            input_tensor = Variable(input_tensor.cuda())\n",
    "\n",
    "        input_batch = input_tensor.unsqueeze(0)\n",
    "        out = model(input_batch)\n",
    "\n",
    "        probabilities = torch.nn.functional.softmax(out[0], dim=0)\n",
    "        # print(probabilities)\n",
    "\n",
    "        with open(\"../../stanford_dogs_breeds_classes_final.txt\", \"r\") as f:\n",
    "            categories = [s.strip() for s in f.readlines()]\n",
    "\n",
    "        predicted_breeds = []\n",
    "        top1_prob, top1_catid = torch.topk(probabilities, 1)\n",
    "        for i in range(top1_prob.size(0)):\n",
    "            # predicted_breeds.append([categories[top3_catid[i]], top3_prob[i].item()*100])\n",
    "            predicted_breed = categories[top1_catid[i]]\n",
    "\n",
    "        # list to be used directly by the application (predicted_breed, probability)\n",
    "        # print(\"predicted_breeds are: \\n\", predicted_breed)\n",
    "        if breed == predicted_breed:\n",
    "            matched = True\n",
    "            matches = matches + 1\n",
    "\n",
    "        per_class_accuracy[breed] = matches / total_images * 100\n",
    "\n",
    "per_class_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.42645461908234"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_accuracy = sum(per_class_accuracy.values())/120\n",
    "total_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 Breeds with least accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Eskimo dog', 46.666666666666664),\n",
       " ('Border collie', 46.666666666666664),\n",
       " ('miniature poodle', 50.0),\n",
       " ('Walker hound', 50.0),\n",
       " ('standard schnauzer', 50.0),\n",
       " ('Siberian husky', 50.0),\n",
       " ('malamute', 55.55555555555556),\n",
       " ('Appenzeller', 56.25),\n",
       " ('Cardigan', 56.25),\n",
       " ('collie', 56.25)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 10\n",
    "sorted(per_class_accuracy.items(), key=lambda x: x[1])[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 15 Breeds with most accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pomeranian', 100.0),\n",
       " ('Blenheim spaniel', 100.0),\n",
       " ('Irish setter', 100.0),\n",
       " ('clumber', 100.0),\n",
       " ('komondor', 100.0),\n",
       " ('Old English sheepdog', 100.0),\n",
       " ('keeshond', 100.0),\n",
       " ('Kerry blue terrier', 100.0),\n",
       " ('groenendael', 100.0),\n",
       " ('Weimaraner', 100.0),\n",
       " ('Saint Bernard', 100.0),\n",
       " ('vizsla', 100.0),\n",
       " ('Shih Tzu', 95.45454545454545),\n",
       " ('Leonberg', 95.23809523809523),\n",
       " ('Airedale', 95.23809523809523)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 15\n",
    "sorted(per_class_accuracy.items(), key=lambda x: x[1], reverse=True)[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
