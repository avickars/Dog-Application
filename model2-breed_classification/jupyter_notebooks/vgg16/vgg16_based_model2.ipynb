{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h6peZN051pRi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNRFuRfY1plM"
   },
   "source": [
    "# Main ML code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "259rbj7O0DW9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import Markdown\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SlUo5Q7x0R3z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lJVn2jF67aDP",
    "outputId": "cd558825-c0d2-429a-9fad-043b3bcb64ed"
   },
   "outputs": [],
   "source": [
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "# material from notebook at: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = '../../../stanford_dogs_new/'\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                              shuffle=True, num_workers=4)\n",
    "               for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "        \n",
    "# # Get a batch of training data\n",
    "# inputs, classes = next(iter(dataloaders['train']))\n",
    "# \n",
    "# # Make a grid from batch\n",
    "# out = torchvision.utils.make_grid(inputs)\n",
    "# \n",
    "# imshow(out, title=[class_names[x] for x in classes])\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "                \n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cx6t5Mvl0R6t",
    "outputId": "713cdc77-8b29-4656-a5c4-c83fe782cf97"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /home/rka73/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab0a758ac1174fb4978eeac9d91a4188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "for param in model_vgg16.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(model_vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uF3Y1Qw56C15"
   },
   "outputs": [],
   "source": [
    "# ref: https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "\n",
    "model_vgg16.classifier = nn.Sequential(*list(model_vgg16.classifier.children())[:-1] + [nn.Linear(in_features=4096, out_features=120, bias=True)])\n",
    "\n",
    "model_vgg16 = model_vgg16.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer_vgg16 = optim.SGD(model_vgg16.classifier.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_vgg16, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "NabXkvLY0R_H",
    "outputId": "7fe63bc5-db0b-4da4-fbd4-b27f1b073e0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.8465 Acc: 0.5568\n",
      "val Loss: 0.7438 Acc: 0.8075\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.7428 Acc: 0.6143\n",
      "val Loss: 0.8626 Acc: 0.8056\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.8193 Acc: 0.6239\n",
      "val Loss: 0.7680 Acc: 0.8163\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.8340 Acc: 0.6335\n",
      "val Loss: 0.9268 Acc: 0.8241\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.8743 Acc: 0.6402\n",
      "val Loss: 0.8416 Acc: 0.8304\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.8351 Acc: 0.6479\n",
      "val Loss: 0.8834 Acc: 0.8309\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.8775 Acc: 0.6500\n",
      "val Loss: 0.8401 Acc: 0.8309\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.6284 Acc: 0.6796\n",
      "val Loss: 0.6941 Acc: 0.8504\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.5689 Acc: 0.6849\n",
      "val Loss: 0.6719 Acc: 0.8558\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.4733 Acc: 0.6981\n",
      "val Loss: 0.6595 Acc: 0.8596\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.4531 Acc: 0.6937\n",
      "val Loss: 0.6509 Acc: 0.8592\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.4168 Acc: 0.6970\n",
      "val Loss: 0.6406 Acc: 0.8558\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.4088 Acc: 0.7015\n",
      "val Loss: 0.6390 Acc: 0.8558\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 1.3588 Acc: 0.7028\n",
      "val Loss: 0.6226 Acc: 0.8626\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.3294 Acc: 0.7106\n",
      "val Loss: 0.6166 Acc: 0.8621\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.3627 Acc: 0.7045\n",
      "val Loss: 0.6109 Acc: 0.8621\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.3449 Acc: 0.7022\n",
      "val Loss: 0.6091 Acc: 0.8611\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.3309 Acc: 0.7082\n",
      "val Loss: 0.6081 Acc: 0.8616\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.3404 Acc: 0.7042\n",
      "val Loss: 0.6089 Acc: 0.8616\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.3186 Acc: 0.7075\n",
      "val Loss: 0.6059 Acc: 0.8611\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.3554 Acc: 0.7048\n",
      "val Loss: 0.6056 Acc: 0.8606\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.3337 Acc: 0.7069\n",
      "val Loss: 0.6054 Acc: 0.8606\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.3416 Acc: 0.7043\n",
      "val Loss: 0.6050 Acc: 0.8606\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.3241 Acc: 0.7092\n",
      "val Loss: 0.6045 Acc: 0.8606\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.3164 Acc: 0.7085\n",
      "val Loss: 0.6042 Acc: 0.8606\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.3274 Acc: 0.7041\n",
      "val Loss: 0.6040 Acc: 0.8606\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.3267 Acc: 0.7090\n",
      "val Loss: 0.6038 Acc: 0.8606\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.3211 Acc: 0.7065\n",
      "val Loss: 0.6038 Acc: 0.8606\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.3392 Acc: 0.7048\n",
      "val Loss: 0.6038 Acc: 0.8606\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.3244 Acc: 0.7064\n",
      "val Loss: 0.6037 Acc: 0.8606\n",
      "\n",
      "Training complete in 37m 59s\n",
      "Best val Acc: 0.862573\n"
     ]
    }
   ],
   "source": [
    "model_vgg16 = train_model(model_vgg16, criterion, optimizer_vgg16, exp_lr_scheduler, num_epochs=30)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MBaGwXwH0chO"
   },
   "outputs": [],
   "source": [
    "torch.save(model_vgg16.state_dict(), 'vgg16_based_model2.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=120, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "for param in model_vgg16.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_vgg16.classifier = nn.Sequential(*list(model_vgg16.classifier.children())[:-1] + [nn.Linear(in_features=4096, out_features=120, bias=True)])\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_vgg16 = model_vgg16.to(device)\n",
    "\n",
    "\n",
    "\n",
    "model_vgg16.load_state_dict(torch.load('vgg16_based_model2.pt'), strict=False)\n",
    "model_vgg16.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the VGG16 model - 30 ep with Adamax optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "for param in vgg16.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "vgg16.classifier = nn.Sequential(*list(vgg16.classifier.children())[:-1] + [nn.Linear(in_features=4096, out_features=120, bias=True)])\n",
    "\n",
    "vgg16 = vgg16.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer_vgg16_adamax = optim.Adamax(vgg16.parameters())\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_vgg16, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.5202 Acc: 0.5917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rka73/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.5235 Acc: 0.8358\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.1215 Acc: 0.6844\n",
      "val Loss: 0.4848 Acc: 0.8470\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.1095 Acc: 0.6962\n",
      "val Loss: 0.4868 Acc: 0.8465\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.1016 Acc: 0.7052\n",
      "val Loss: 0.4912 Acc: 0.8484\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.1015 Acc: 0.7085\n",
      "val Loss: 0.4946 Acc: 0.8548\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.0947 Acc: 0.7172\n",
      "val Loss: 0.4854 Acc: 0.8562\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.1207 Acc: 0.7152\n",
      "val Loss: 0.4980 Acc: 0.8519\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.0858 Acc: 0.7273\n",
      "val Loss: 0.5056 Acc: 0.8514\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.0944 Acc: 0.7254\n",
      "val Loss: 0.4919 Acc: 0.8621\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.1014 Acc: 0.7275\n",
      "val Loss: 0.5030 Acc: 0.8553\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.0935 Acc: 0.7345\n",
      "val Loss: 0.5020 Acc: 0.8635\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.1365 Acc: 0.7280\n",
      "val Loss: 0.5203 Acc: 0.8611\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.1351 Acc: 0.7271\n",
      "val Loss: 0.5162 Acc: 0.8635\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 1.1096 Acc: 0.7371\n",
      "val Loss: 0.5119 Acc: 0.8587\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.1273 Acc: 0.7285\n",
      "val Loss: 0.5201 Acc: 0.8538\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.1292 Acc: 0.7333\n",
      "val Loss: 0.5137 Acc: 0.8562\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.1019 Acc: 0.7380\n",
      "val Loss: 0.5099 Acc: 0.8548\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.1394 Acc: 0.7321\n",
      "val Loss: 0.5170 Acc: 0.8548\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.1143 Acc: 0.7366\n",
      "val Loss: 0.5075 Acc: 0.8582\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.1492 Acc: 0.7392\n",
      "val Loss: 0.5240 Acc: 0.8533\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.1176 Acc: 0.7427\n",
      "val Loss: 0.5080 Acc: 0.8596\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.1311 Acc: 0.7382\n",
      "val Loss: 0.5235 Acc: 0.8592\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.1437 Acc: 0.7387\n",
      "val Loss: 0.5148 Acc: 0.8635\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.1357 Acc: 0.7408\n",
      "val Loss: 0.5411 Acc: 0.8489\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.1396 Acc: 0.7408\n",
      "val Loss: 0.5289 Acc: 0.8601\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.1705 Acc: 0.7405\n",
      "val Loss: 0.5293 Acc: 0.8538\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.1470 Acc: 0.7447\n",
      "val Loss: 0.5452 Acc: 0.8509\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.1907 Acc: 0.7383\n",
      "val Loss: 0.5320 Acc: 0.8499\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.1643 Acc: 0.7409\n",
      "val Loss: 0.5325 Acc: 0.8538\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.1339 Acc: 0.7489\n",
      "val Loss: 0.5385 Acc: 0.8519\n",
      "\n",
      "Training complete in 38m 15s\n",
      "Best val Acc: 0.863548\n"
     ]
    }
   ],
   "source": [
    "vgg16_adamax_30ep = train_model(vgg16, criterion, optimizer_vgg16_adamax, exp_lr_scheduler, num_epochs=30)\n",
    "\n",
    "# %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vgg16_adamax_30ep.state_dict(), 'vgg16_adamax_30ep_based_model2.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Adamax optimizer based vgg16 model and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Linear(in_features=4096, out_features=120, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16_adamax_30ep_loaded = models.vgg16(pretrained=True)\n",
    "\n",
    "for param in vgg16_adamax_30ep_loaded.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "vgg16_adamax_30ep_loaded.classifier = nn.Linear(in_features=4096, out_features=120, bias=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "vgg16_adamax_30ep_loaded = vgg16_adamax_30ep_loaded.to(device)\n",
    "\n",
    "\n",
    "\n",
    "vgg16_adamax_30ep_loaded.load_state_dict(torch.load('vgg16_adamax_30ep_based_model2.pt'), strict=False)\n",
    "vgg16_adamax_30ep_loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "vgg16-based-model2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
