{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h6peZN051pRi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNRFuRfY1plM"
   },
   "source": [
    "# Main ML code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "259rbj7O0DW9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import Markdown\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SlUo5Q7x0R3z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lJVn2jF67aDP",
    "outputId": "cd558825-c0d2-429a-9fad-043b3bcb64ed"
   },
   "outputs": [],
   "source": [
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "# material from notebook at: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = '../../stanford_dogs_new/'\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                              shuffle=True, num_workers=4)\n",
    "               for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "        \n",
    "# # Get a batch of training data\n",
    "# inputs, classes = next(iter(dataloaders['train']))\n",
    "# \n",
    "# # Make a grid from batch\n",
    "# out = torchvision.utils.make_grid(inputs)\n",
    "# \n",
    "# imshow(out, title=[class_names[x] for x in classes])\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "                \n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cx6t5Mvl0R6t",
    "outputId": "713cdc77-8b29-4656-a5c4-c83fe782cf97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): ReLU(inplace=True)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): ReLU(inplace=True)\n",
      "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (33): ReLU(inplace=True)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): ReLU(inplace=True)\n",
      "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vgg19 = models.vgg19(pretrained=True)\n",
    "\n",
    "for param in vgg19.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(vgg19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uF3Y1Qw56C15"
   },
   "outputs": [],
   "source": [
    "# ref: https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "\n",
    "vgg19.classifier[6] = nn.Linear(in_features=4096, out_features=120, bias=True)\n",
    "\n",
    "vgg19 = vgg19.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer_vgg19 = optim.SGD(vgg19.parameters(), lr=0.001, momentum=0.9)\n",
    "# optimizer_vgg19 = optim.Adamax(vgg19.parameters())\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_vgg19, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "NabXkvLY0R_H",
    "outputId": "7fe63bc5-db0b-4da4-fbd4-b27f1b073e0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/59\n",
      "----------\n",
      "train Loss: 1.7241 Acc: 0.5777\n",
      "val Loss: 0.7040 Acc: 0.7997\n",
      "\n",
      "Epoch 1/59\n",
      "----------\n",
      "train Loss: 1.5910 Acc: 0.6375\n",
      "val Loss: 0.5949 Acc: 0.8358\n",
      "\n",
      "Epoch 2/59\n",
      "----------\n",
      "train Loss: 1.6388 Acc: 0.6451\n",
      "val Loss: 0.6576 Acc: 0.8392\n",
      "\n",
      "Epoch 3/59\n",
      "----------\n",
      "train Loss: 1.6604 Acc: 0.6571\n",
      "val Loss: 0.7583 Acc: 0.8270\n",
      "\n",
      "Epoch 4/59\n",
      "----------\n",
      "train Loss: 1.7007 Acc: 0.6543\n",
      "val Loss: 0.6774 Acc: 0.8406\n",
      "\n",
      "Epoch 5/59\n",
      "----------\n",
      "train Loss: 1.7150 Acc: 0.6654\n",
      "val Loss: 0.7652 Acc: 0.8304\n",
      "\n",
      "Epoch 6/59\n",
      "----------\n",
      "train Loss: 1.7341 Acc: 0.6670\n",
      "val Loss: 0.7492 Acc: 0.8377\n",
      "\n",
      "Epoch 7/59\n",
      "----------\n",
      "train Loss: 1.4793 Acc: 0.6950\n",
      "val Loss: 0.5792 Acc: 0.8553\n",
      "\n",
      "Epoch 8/59\n",
      "----------\n",
      "train Loss: 1.4142 Acc: 0.7054\n",
      "val Loss: 0.5701 Acc: 0.8611\n",
      "\n",
      "Epoch 9/59\n",
      "----------\n",
      "train Loss: 1.3626 Acc: 0.7068\n",
      "val Loss: 0.5571 Acc: 0.8582\n",
      "\n",
      "Epoch 10/59\n",
      "----------\n",
      "train Loss: 1.3323 Acc: 0.7080\n",
      "val Loss: 0.5375 Acc: 0.8621\n",
      "\n",
      "Epoch 11/59\n",
      "----------\n",
      "train Loss: 1.3263 Acc: 0.7065\n",
      "val Loss: 0.5335 Acc: 0.8635\n",
      "\n",
      "Epoch 12/59\n",
      "----------\n",
      "train Loss: 1.3110 Acc: 0.7103\n",
      "val Loss: 0.5324 Acc: 0.8606\n",
      "\n",
      "Epoch 13/59\n",
      "----------\n",
      "train Loss: 1.2766 Acc: 0.7149\n",
      "val Loss: 0.5351 Acc: 0.8631\n",
      "\n",
      "Epoch 14/59\n",
      "----------\n",
      "train Loss: 1.2613 Acc: 0.7196\n",
      "val Loss: 0.5250 Acc: 0.8640\n",
      "\n",
      "Epoch 15/59\n",
      "----------\n",
      "train Loss: 1.2533 Acc: 0.7221\n",
      "val Loss: 0.5163 Acc: 0.8665\n",
      "\n",
      "Epoch 16/59\n",
      "----------\n",
      "train Loss: 1.2321 Acc: 0.7189\n",
      "val Loss: 0.5158 Acc: 0.8674\n",
      "\n",
      "Epoch 17/59\n",
      "----------\n",
      "train Loss: 1.2487 Acc: 0.7191\n",
      "val Loss: 0.5136 Acc: 0.8645\n",
      "\n",
      "Epoch 18/59\n",
      "----------\n",
      "train Loss: 1.2388 Acc: 0.7167\n",
      "val Loss: 0.5113 Acc: 0.8660\n",
      "\n",
      "Epoch 19/59\n",
      "----------\n",
      "train Loss: 1.2393 Acc: 0.7198\n",
      "val Loss: 0.5099 Acc: 0.8660\n",
      "\n",
      "Epoch 20/59\n",
      "----------\n",
      "train Loss: 1.2299 Acc: 0.7192\n",
      "val Loss: 0.5093 Acc: 0.8650\n",
      "\n",
      "Epoch 21/59\n",
      "----------\n",
      "train Loss: 1.2433 Acc: 0.7168\n",
      "val Loss: 0.5092 Acc: 0.8650\n",
      "\n",
      "Epoch 22/59\n",
      "----------\n",
      "train Loss: 1.2083 Acc: 0.7223\n",
      "val Loss: 0.5092 Acc: 0.8645\n",
      "\n",
      "Epoch 23/59\n",
      "----------\n",
      "train Loss: 1.2258 Acc: 0.7260\n",
      "val Loss: 0.5093 Acc: 0.8650\n",
      "\n",
      "Epoch 24/59\n",
      "----------\n",
      "train Loss: 1.2256 Acc: 0.7219\n",
      "val Loss: 0.5090 Acc: 0.8655\n",
      "\n",
      "Epoch 25/59\n",
      "----------\n",
      "train Loss: 1.2340 Acc: 0.7200\n",
      "val Loss: 0.5090 Acc: 0.8650\n",
      "\n",
      "Epoch 26/59\n",
      "----------\n",
      "train Loss: 1.2277 Acc: 0.7227\n",
      "val Loss: 0.5088 Acc: 0.8650\n",
      "\n",
      "Epoch 27/59\n",
      "----------\n",
      "train Loss: 1.2435 Acc: 0.7177\n",
      "val Loss: 0.5087 Acc: 0.8655\n",
      "\n",
      "Epoch 28/59\n",
      "----------\n",
      "train Loss: 1.2202 Acc: 0.7213\n",
      "val Loss: 0.5087 Acc: 0.8655\n",
      "\n",
      "Epoch 29/59\n",
      "----------\n",
      "train Loss: 1.2095 Acc: 0.7251\n",
      "val Loss: 0.5087 Acc: 0.8655\n",
      "\n",
      "Epoch 30/59\n",
      "----------\n",
      "train Loss: 1.2506 Acc: 0.7200\n",
      "val Loss: 0.5087 Acc: 0.8655\n",
      "\n",
      "Epoch 31/59\n",
      "----------\n",
      "train Loss: 1.2543 Acc: 0.7150\n",
      "val Loss: 0.5087 Acc: 0.8655\n",
      "\n",
      "Epoch 32/59\n",
      "----------\n",
      "train Loss: 1.2149 Acc: 0.7212\n",
      "val Loss: 0.5087 Acc: 0.8655\n",
      "\n",
      "Epoch 33/59\n",
      "----------\n",
      "train Loss: 1.2142 Acc: 0.7226\n",
      "val Loss: 0.5087 Acc: 0.8655\n",
      "\n",
      "Epoch 34/59\n",
      "----------\n",
      "train Loss: 1.2547 Acc: 0.7168\n",
      "val Loss: 0.5087 Acc: 0.8660\n",
      "\n",
      "Epoch 35/59\n",
      "----------\n",
      "train Loss: 1.2105 Acc: 0.7213\n",
      "val Loss: 0.5087 Acc: 0.8660\n",
      "\n",
      "Epoch 36/59\n",
      "----------\n",
      "train Loss: 1.2129 Acc: 0.7211\n",
      "val Loss: 0.5087 Acc: 0.8660\n",
      "\n",
      "Epoch 37/59\n",
      "----------\n",
      "train Loss: 1.2195 Acc: 0.7236\n",
      "val Loss: 0.5087 Acc: 0.8660\n",
      "\n",
      "Epoch 38/59\n",
      "----------\n",
      "train Loss: 1.2313 Acc: 0.7199\n",
      "val Loss: 0.5087 Acc: 0.8660\n",
      "\n",
      "Epoch 39/59\n",
      "----------\n",
      "train Loss: 1.1953 Acc: 0.7249\n",
      "val Loss: 0.5087 Acc: 0.8660\n",
      "\n",
      "Epoch 40/59\n",
      "----------\n",
      "train Loss: 1.2397 Acc: 0.7190\n",
      "val Loss: 0.5087 Acc: 0.8660\n",
      "\n",
      "Epoch 41/59\n",
      "----------\n",
      "train Loss: 1.2038 Acc: 0.7249\n",
      "val Loss: 0.5087 Acc: 0.8660\n",
      "\n",
      "Epoch 42/59\n",
      "----------\n",
      "train Loss: 1.2153 Acc: 0.7223\n",
      "val Loss: 0.5087 Acc: 0.8660\n",
      "\n",
      "Epoch 43/59\n",
      "----------\n",
      "train Loss: 1.2357 Acc: 0.7191\n",
      "val Loss: 0.5087 Acc: 0.8660\n",
      "\n",
      "Epoch 44/59\n",
      "----------\n",
      "train Loss: 1.2718 Acc: 0.7115\n",
      "val Loss: 0.5087 Acc: 0.8660\n",
      "\n",
      "Epoch 45/59\n",
      "----------\n",
      "train Loss: 1.2087 Acc: 0.7280\n",
      "val Loss: 0.5087 Acc: 0.8660\n",
      "\n",
      "Epoch 46/59\n",
      "----------\n",
      "train Loss: 1.2144 Acc: 0.7218\n",
      "val Loss: 0.5087 Acc: 0.8660\n",
      "\n",
      "Epoch 47/59\n",
      "----------\n",
      "train Loss: 1.2446 Acc: 0.7186\n",
      "val Loss: 0.5087 Acc: 0.8660\n",
      "\n",
      "Epoch 48/59\n",
      "----------\n",
      "train Loss: 1.2246 Acc: 0.7214\n",
      "val Loss: 0.5087 Acc: 0.8660\n",
      "\n",
      "Epoch 49/59\n",
      "----------\n",
      "train Loss: 1.2290 Acc: 0.7227\n",
      "val Loss: 0.5087 Acc: 0.8660\n",
      "\n",
      "Epoch 50/59\n",
      "----------\n",
      "train Loss: 1.2335 Acc: 0.7209\n",
      "val Loss: 0.5087 Acc: 0.8660\n",
      "\n",
      "Epoch 51/59\n",
      "----------\n",
      "train Loss: 1.1959 Acc: 0.7262\n",
      "val Loss: 0.5087 Acc: 0.8660\n",
      "\n",
      "Epoch 52/59\n",
      "----------\n",
      "train Loss: 1.2337 Acc: 0.7195\n",
      "val Loss: 0.5087 Acc: 0.8660\n",
      "\n",
      "Epoch 53/59\n",
      "----------\n",
      "train Loss: 1.2201 Acc: 0.7240\n",
      "val Loss: 0.5087 Acc: 0.8660\n",
      "\n",
      "Epoch 54/59\n",
      "----------\n",
      "train Loss: 1.2385 Acc: 0.7179\n",
      "val Loss: 0.5087 Acc: 0.8660\n",
      "\n",
      "Epoch 55/59\n",
      "----------\n",
      "train Loss: 1.2599 Acc: 0.7196\n",
      "val Loss: 0.5087 Acc: 0.8660\n",
      "\n",
      "Epoch 56/59\n",
      "----------\n",
      "train Loss: 1.1904 Acc: 0.7260\n",
      "val Loss: 0.5087 Acc: 0.8660\n",
      "\n",
      "Epoch 57/59\n",
      "----------\n",
      "train Loss: 1.2089 Acc: 0.7249\n",
      "val Loss: 0.5087 Acc: 0.8660\n",
      "\n",
      "Epoch 58/59\n",
      "----------\n",
      "train Loss: 1.2283 Acc: 0.7270\n",
      "val Loss: 0.5087 Acc: 0.8660\n",
      "\n",
      "Epoch 59/59\n",
      "----------\n",
      "train Loss: 1.2230 Acc: 0.7234\n",
      "val Loss: 0.5087 Acc: 0.8660\n",
      "\n",
      "Training complete in 1545m 13s\n",
      "Best val Acc: 0.867446\n"
     ]
    }
   ],
   "source": [
    "vgg19_30 = train_model(vgg19, criterion, optimizer_vgg19, exp_lr_scheduler, num_epochs=30)\n",
    "\n",
    "# %\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "MBaGwXwH0chO"
   },
   "outputs": [],
   "source": [
    "torch.save(vgg19_30.state_dict(), 'vgg19_based_model2.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for VGG:\n\tsize mismatch for classifier.6.weight: copying a param with shape torch.Size([120, 4096]) from checkpoint, the shape in current model is torch.Size([1000, 4096]).\n\tsize mismatch for classifier.6.bias: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([1000]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17607/2682417471.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mvgg19_60_loaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vgg19_60_based_model2.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mvgg19_60_loaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1497\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1498\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1499\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for VGG:\n\tsize mismatch for classifier.6.weight: copying a param with shape torch.Size([120, 4096]) from checkpoint, the shape in current model is torch.Size([1000, 4096]).\n\tsize mismatch for classifier.6.bias: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([1000])."
     ]
    }
   ],
   "source": [
    "vgg19_loaded = models.vgg19(pretrained=True)\n",
    "\n",
    "for param in vgg19_loaded.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "vgg19_loaded.fc = nn.Linear(in_features=4096, out_features=120, bias=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "vgg19_loaded = vgg19_60_loaded.to(device)\n",
    "\n",
    "\n",
    "\n",
    "vgg19_loaded.load_state_dict(torch.load('vgg19_based_model2.pt'), strict=False)\n",
    "vgg19_loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train vgg19 with Adamax optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "\n",
    "vgg19.classifier[6] = nn.Linear(in_features=4096, out_features=120, bias=True)\n",
    "\n",
    "vgg19 = vgg19.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "# optimizer_vgg19 = optim.SGD(vgg19.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer_vgg19_adamax = optim.Adamax(vgg19.parameters())\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_vgg19_adamax, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_adamax_30ep = train_model(vgg19, criterion, optimizer_vgg19_adamax, exp_lr_scheduler, num_epochs=30)\n",
    "\n",
    "# %\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vgg19_adamax_30ep.state_dict(), 'vgg19_adamax_30ep_based_model2.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Adamax optimizer based vgg19 model and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_adamax_30ep_loaded = models.vgg19(pretrained=True)\n",
    "\n",
    "for param in vgg19_adamax_30ep_loaded.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "vgg19_adamax_30ep_loaded.fc = nn.Linear(in_features=4096, out_features=120, bias=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "vgg19_adamax_30ep_loaded = vgg19_adamax_30ep_loaded.to(device)\n",
    "\n",
    "\n",
    "\n",
    "vgg19_adamax_30ep_loaded.load_state_dict(torch.load('vgg19_adamax_30ep_based_model2.pt'), strcit=False)\n",
    "vgg19_adamax_30ep_loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "vgg16-based-model2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
