{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "612545d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import OpenImagesDataset, collate_fn\n",
    "from model_utils import plot_tensor, plot_image\n",
    "from model_transformations import Transformations\n",
    "from torch.utils.data import DataLoader\n",
    "from params import DEVICE, CPU_DEVICE\n",
    "from model import DogDetectorModel\n",
    "import torch\n",
    "from model_trainer import trainer\n",
    "from model_evaluator import evaluator\n",
    "from non_max_surpression import NonMaxSurpression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03ee40eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the model\n",
    "model = DogDetectorModel()\n",
    "\n",
    "# Moving to training device\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a05a4405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the training data\n",
    "trainingData = OpenImagesDataset(rootDirectory='open-images-v6',\n",
    "                                 transform=Transformations, \n",
    "                                 dataType='train')    \n",
    "\n",
    "# Defining the training data\n",
    "trainDataLoader = DataLoader(dataset=trainingData, \n",
    "                             batch_size=2,\n",
    "                             num_workers=4,\n",
    "                             shuffle=False, collate_fn=collate_fn, pin_memory=True)\n",
    "\n",
    "# Reading in the training data\n",
    "validationData = OpenImagesDataset(rootDirectory='open-images-v6',\n",
    "                                 transform=Transformations, \n",
    "                                 dataType='validation')    \n",
    "\n",
    "# Defining the training data\n",
    "validationDataLoader = DataLoader(dataset=validationData, \n",
    "                             batch_size=1,\n",
    "                             num_workers=2,\n",
    "                             shuffle=False, collate_fn=collate_fn, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "638ecbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                            momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# Defining the learning rate that makes a step every 3 epochs\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                               step_size=3,\n",
    "                                               gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44e2b7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "121d910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_MAP = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9366dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                          | 0/2500 [00:00<?, ?it/s]/home/aidan/Programs/miniconda3/envs/dogapp/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "EPOCH: 0 | Classifier Loss 0.03292204067111015 | Bbox Loss: 0.03833835572004318 | Objectness Loss 0.002500746166333556 | Loss 0.12397029995918274:  60%|████████████████████████████████████████████████████████████████▎                                           | 1489/2500 [07:23<04:57,  3.40it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    # ***************** TRAINING ******************    \n",
    "\n",
    "    trainer(model, optimizer, trainDataLoader, epoch)\n",
    "    \n",
    "    # Updating the learning rate scheduler\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    # ***************** EVALUATION ******************    \n",
    "\n",
    "    coco_evaluator, MAP = evaluator(model, validationDataLoader)\n",
    "    \n",
    "    print('MAP:', MAP)\n",
    "    \n",
    "    if MAP > BEST_MAP:\n",
    "        print('Saving New Model')\n",
    "        PATH = \"model.pt\"\n",
    "        torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': MAP,\n",
    "        }, PATH)\n",
    "        \n",
    "        BEST_MAP = MAP\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a73e3f",
   "metadata": {},
   "source": [
    "# Loading and View Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e9a12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nms = NonMaxSurpression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46731e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('model.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21374296",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = next(iter(validationDataLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85930c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = list(image.to(DEVICE) for image in images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f55a548",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "outputs = model(images, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67768185",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [{k: v.to(CPU_DEVICE) for k, v in t.items()} for t in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0e978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [img.to(CPU_DEVICE) for img in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b18bca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = nms(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ba23cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(images)):\n",
    "    plot_tensor(images[i],targets[i]['boxes'], outputs[i]['boxes'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
