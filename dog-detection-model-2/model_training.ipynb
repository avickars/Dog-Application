{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "612545d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import OpenImagesDataset, collate_fn\n",
    "from model_utils import plot_tensor, plot_image\n",
    "from model_transformations import Transformations\n",
    "from torch.utils.data import DataLoader\n",
    "from params import DEVICE\n",
    "from model import DogDetectorModel\n",
    "import torch\n",
    "from model_trainer import trainer\n",
    "from model_evaluator import evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38c337fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the model\n",
    "model = DogDetectorModel()\n",
    "\n",
    "# Moving to training device\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b2c2184",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a05a4405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the training data\n",
    "trainingData = OpenImagesDataset(rootDirectory='open-images-v6',\n",
    "                                 transform=Transformations, \n",
    "                                 dataType='train')    \n",
    "\n",
    "# Defining the training data\n",
    "trainDataLoader = DataLoader(dataset=trainingData, \n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             num_workers=4,\n",
    "                             shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# Reading in the training data\n",
    "validationData = OpenImagesDataset(rootDirectory='open-images-v6',\n",
    "                                 transform=Transformations, \n",
    "                                 dataType='validation')    \n",
    "\n",
    "# Defining the training data\n",
    "validationDataLoader = DataLoader(dataset=validationData, \n",
    "                             batch_size=1,\n",
    "                             num_workers=2,\n",
    "                             shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "047d2c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                            momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# Defining the learning rate that makes a step every 3 epochs\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                               step_size=3,\n",
    "                                               gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af9261b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b85e2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                          | 0/500 [00:00<?, ?it/s]/home/aidan/Programs/miniconda3/envs/dogapp/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "EPOCH: 0 | Classifier Loss 0.03860253468155861 | Bbox Loss: 0.05920293554663658 | Objectness Loss 0.005157435312867165 | Loss 0.11637904495000839: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [02:38<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 14.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.900\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.900\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.900\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.900\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.900\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH: 1 | Classifier Loss 0.024352915585041046 | Bbox Loss: 0.040665872395038605 | Objectness Loss 0.0009331000037491322 | Loss 0.06892501562833786:  38%|██████████████████████████████████                                                        | 189/500 [00:57<01:29,  3.47it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    # ***************** TRAINING ******************    \n",
    "\n",
    "    trainer(model, optimizer, trainDataLoader, epoch)\n",
    "    \n",
    "    # Updating the learning rate scheduler\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    # ***************** EVALUATION ******************    \n",
    "\n",
    "    x = evaluator(model, validationDataLoader)\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceabb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"model.pt\"\n",
    "torch.save({\n",
    "'epoch': EPOCH,\n",
    "'model_state_dict': mdoel.state_dict(),\n",
    "'optimizer_state_dict': optimizer.state_dict(),\n",
    "'loss': -1,\n",
    "}, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eae36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tensor(images.cpu(),outputs[0]['boxes'][0].reshape((1,-1)).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5e2040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
